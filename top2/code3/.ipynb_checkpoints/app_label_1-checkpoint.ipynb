{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from help_function import LoadData\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- deviceid_packages.tsv\n",
    "- package_label.tsv\n",
    "- deviceid_train.tsv\n",
    "----------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "app_label = pd.read_csv('../Demo/package_label.tsv',sep='\\t',names=['app_id','label_1','label_2'])\n",
    "device_applist = pd.read_csv('../Demo/deviceid_packages.tsv',sep='\\t',names=['device_id','app_names'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "device_applist['app_names']=device_applist['app_names'].apply(lambda x:x.split(','))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 去掉冗余label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "app_label.label_1 = app_label.label_1.apply(lambda x:x.split('(')[0])\n",
    "app_label.label_2 = app_label.label_2.apply(lambda x:x.split('/')[0])\n",
    "app_label.label_2 = app_label.label_2.apply(lambda x:x.split('(')[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### app_id : label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "app_label = app_label.set_index('app_id')\n",
    "# app_id : label_1\n",
    "label1_dict = app_label.label_1.to_dict()\n",
    "# app_id : label_2\n",
    "label2_dict = app_label.label_2.to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 设备安装应用列表label数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# app_id 转换为 label1, label2\n",
    "device_applist['label_1'] = device_applist.app_names.apply(lambda x:','.join([label1_dict[key] if key in label1_dict else 'unknow' for key in x])) \n",
    "\n",
    "device_applist['label_2'] = device_applist.app_names.apply(lambda x:','.join([label2_dict[key] if key in label2_dict else 'unknow' for key in x]))\n",
    "\n",
    "# conversion to list\n",
    "device_applist['label_1'] = device_applist.label_1.apply(lambda x:x.split(','))\n",
    "\n",
    "device_applist['label_2'] = device_applist.label_2.apply(lambda x:x.split(','))\n",
    "\n",
    "label1s = device_applist.label_1.apply(lambda x:' '.join(x)).tolist()\n",
    "\n",
    "label2s = device_applist.label_2.apply(lambda x:' '.join(x)).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "transformer=TfidfTransformer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------\n",
    "## label_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# label1 count vector\n",
    "label1_cntvector = vectorizer.fit_transform(label1s)\n",
    "\n",
    "label1_tfidf = transformer.fit_transform(label1_cntvector)\n",
    "\n",
    "label1_vocabulary =  pd.DataFrame.from_dict(vectorizer.vocabulary_,orient='index')\n",
    "\n",
    "label1_names = list(label1_vocabulary.sort_values(by=0).index)\n",
    "\n",
    "# label1 CountVector\n",
    "label1_cnt =pd.DataFrame(label1_cntvector.toarray(),columns=label1_names)\n",
    "\n",
    "label1_cnt['device_id'] = device_applist.device_id.values\n",
    "\n",
    "# label1  Tfidf\n",
    "label1_tfidf = pd.DataFrame(label1_tfidf.toarray(),columns=label1_names)\n",
    "\n",
    "label1_tfidf['device_id'] = device_applist.device_id.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------\n",
    "### label2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "label2_vectorizer = CountVectorizer()\n",
    "\n",
    "label2_cntvector = label2_vectorizer.fit_transform(label2s)\n",
    "label2_tfidf = transformer.fit_transform(label2_cntvector)\n",
    "\n",
    "label2_vocabulary =  pd.DataFrame.from_dict(label2_vectorizer.vocabulary_,orient='index')\n",
    "\n",
    "label2_names = list(label2_vocabulary.sort_values(by=0).index)\n",
    "\n",
    "label2_cnt = pd.DataFrame(label2_cntvector.toarray(),columns=label2_names)\n",
    "label2_cnt['device_id'] = device_applist.device_id.values\n",
    "\n",
    "label2_tfidf = pd.DataFrame(label2_tfidf.toarray(),columns=label2_names)\n",
    "label2_tfidf['device_id'] = device_applist.device_id.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Merge label1 label2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "label_cnt = label1_cnt.merge(label2_cnt, on='device_id', how='left')\n",
    "\n",
    "label_tfidf= label1_tfidf.merge(label2_tfidf, on='device_id',how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load trian test data\n",
    "train_datapath =  '../Demo/deviceid_train.tsv' \n",
    "test_datapath =  '../Demo/deviceid_test.tsv' \n",
    "train_data, test_data = LoadData(train_datapath, test_datapath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------\n",
    "## Merge data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data = train_data.merge(label_tfidf,on='device_id',how='left')\n",
    "\n",
    "test_data = test_data.merge(label_tfidf, on='device_id',how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------\n",
    "# Train code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold,StratifiedKFold\n",
    "from sklearn.metrics import log_loss\n",
    "import warnings\n",
    "import gc\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_code(train_data, test_data,label, num_class, n_folds=5):\n",
    "    labels = train_data[[label]]\n",
    "    train_data = train_data.drop(['device_id','sex','age','label'],axis=1)\n",
    "    test_data = test_data.drop(['device_id'],axis=1)\n",
    "    train_predvec = np.zeros((train_data.shape[0], num_class))\n",
    "    test_predvec = np.zeros((test_data.shape[0], num_class))\n",
    "    SKF = StratifiedKFold(n_splits = n_folds, shuffle = True, random_state = 2018)\n",
    "    train_logloss = []\n",
    "    valid_logloss = []\n",
    "    for train_indices, valid_indices in SKF.split(train_data,labels):\n",
    "        # Training data for the fold\n",
    "        x_train = train_data.loc[train_indices, :]\n",
    "        y_train = labels.loc[train_indices, :]\n",
    "        # Validation data for the fold\n",
    "        x_valid = train_data.loc[valid_indices, :]\n",
    "        y_valid = labels.loc[valid_indices, :]\n",
    "        # Model\n",
    "        model = MLPClassifier(hidden_layer_sizes=(200,200,200),  #300,300,300\n",
    "                     alpha=0.0001,            # 0.00013\n",
    "                     batch_size=128,\n",
    "                     learning_rate='adaptive',\n",
    "                     learning_rate_init=0.00054321,\n",
    "                     random_state=666,\n",
    "                     tol = 0.005,\n",
    "                     verbose=False,\n",
    "                     early_stopping=True,\n",
    "                     validation_fraction=0.1)       \n",
    "        model.fit(x_train, y_train)\n",
    "        train_predvec[valid_indices] = model.predict_proba(x_valid)\n",
    "        test_predvec += model.predict_proba(test_data)/n_folds\n",
    "        # Clean up memory\n",
    "        gc.enable()\n",
    "        del model, x_train, y_train, x_valid, y_valid\n",
    "        gc.collect()\n",
    "    return train_predvec, test_predvec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 2.87704133\n",
      "Validation score: 0.116915\n",
      "Iteration 2, loss = 2.80892552\n",
      "Validation score: 0.116915\n",
      "Iteration 3, loss = 2.79004198\n",
      "Validation score: 0.120027\n",
      "Iteration 4, loss = 2.77776653\n",
      "Validation score: 0.122249\n",
      "Validation score did not improve more than tol=0.005000 for two consecutive epochs. Stopping.\n",
      "############## one flod is over ##############\n",
      "Iteration 1, loss = 2.88235327\n",
      "Validation score: 0.110000\n",
      "Iteration 2, loss = 2.81449786\n",
      "Validation score: 0.118000\n",
      "Iteration 3, loss = 2.79365796\n",
      "Validation score: 0.118667\n",
      "Iteration 4, loss = 2.78062092\n",
      "Validation score: 0.116889\n",
      "Iteration 5, loss = 2.77185030\n",
      "Validation score: 0.120889\n",
      "Validation score did not improve more than tol=0.005000 for two consecutive epochs. Stopping.\n",
      "############## one flod is over ##############\n",
      "Iteration 1, loss = 2.87869011\n",
      "Validation score: 0.109556\n",
      "Iteration 2, loss = 2.81131301\n",
      "Validation score: 0.112444\n",
      "Iteration 3, loss = 2.79143581\n",
      "Validation score: 0.115111\n",
      "Iteration 4, loss = 2.78090683\n",
      "Validation score: 0.122667\n",
      "Iteration 5, loss = 2.77028973\n",
      "Validation score: 0.118000\n",
      "Iteration 6, loss = 2.76191278\n",
      "Validation score: 0.112889\n",
      "Iteration 7, loss = 2.75281435\n",
      "Validation score: 0.114667\n",
      "Validation score did not improve more than tol=0.005000 for two consecutive epochs. Stopping.\n",
      "############## one flod is over ##############\n",
      "Iteration 1, loss = 2.88189213\n",
      "Validation score: 0.106667\n",
      "Iteration 2, loss = 2.81459580\n",
      "Validation score: 0.117778\n",
      "Iteration 3, loss = 2.79479426\n",
      "Validation score: 0.123556\n",
      "Iteration 4, loss = 2.78158545\n",
      "Validation score: 0.125556\n",
      "Iteration 5, loss = 2.77063369\n",
      "Validation score: 0.123333\n",
      "Iteration 6, loss = 2.76182391\n",
      "Validation score: 0.128444\n",
      "Validation score did not improve more than tol=0.005000 for two consecutive epochs. Stopping.\n",
      "############## one flod is over ##############\n",
      "Iteration 1, loss = 2.88109073\n",
      "Validation score: 0.112667\n",
      "Iteration 2, loss = 2.81548609\n",
      "Validation score: 0.113111\n",
      "Iteration 3, loss = 2.79507238\n",
      "Validation score: 0.112222\n",
      "Iteration 4, loss = 2.78124834\n",
      "Validation score: 0.124222\n",
      "Iteration 5, loss = 2.77106958\n",
      "Validation score: 0.120889\n",
      "Iteration 6, loss = 2.76206779\n",
      "Validation score: 0.112444\n",
      "Iteration 7, loss = 2.75342792\n",
      "Validation score: 0.117333\n",
      "Validation score did not improve more than tol=0.005000 for two consecutive epochs. Stopping.\n",
      "############## one flod is over ##############\n",
      "Iteration 1, loss = 2.88458191\n",
      "Validation score: 0.109087\n",
      "Iteration 2, loss = 2.81578409\n",
      "Validation score: 0.117307\n",
      "Iteration 3, loss = 2.79543484\n",
      "Validation score: 0.119307\n",
      "Iteration 4, loss = 2.78262249\n",
      "Validation score: 0.121751\n",
      "Iteration 5, loss = 2.77260245\n",
      "Validation score: 0.127305\n",
      "Iteration 6, loss = 2.76362055\n",
      "Validation score: 0.123750\n",
      "Iteration 7, loss = 2.75377857\n",
      "Validation score: 0.126639\n",
      "Iteration 8, loss = 2.74437577\n",
      "Validation score: 0.119307\n",
      "Validation score did not improve more than tol=0.005000 for two consecutive epochs. Stopping.\n",
      "############## one flod is over ##############\n",
      "Iteration 1, loss = 2.87828112\n",
      "Validation score: 0.107754\n",
      "Iteration 2, loss = 2.81031887\n",
      "Validation score: 0.119751\n",
      "Iteration 3, loss = 2.78947336\n",
      "Validation score: 0.118196\n",
      "Iteration 4, loss = 2.77803449\n",
      "Validation score: 0.113752\n",
      "Iteration 5, loss = 2.76755533\n",
      "Validation score: 0.119751\n",
      "Validation score did not improve more than tol=0.005000 for two consecutive epochs. Stopping.\n",
      "############## one flod is over ##############\n",
      "Iteration 1, loss = 2.88080902\n",
      "Validation score: 0.113308\n",
      "Iteration 2, loss = 2.81358708\n",
      "Validation score: 0.117752\n",
      "Iteration 3, loss = 2.79331404\n",
      "Validation score: 0.120640\n",
      "Iteration 4, loss = 2.78097251\n",
      "Validation score: 0.121529\n",
      "Validation score did not improve more than tol=0.005000 for two consecutive epochs. Stopping.\n",
      "############## one flod is over ##############\n",
      "Iteration 1, loss = 2.88188134\n",
      "Validation score: 0.107754\n",
      "Iteration 2, loss = 2.81408398\n",
      "Validation score: 0.113308\n",
      "Iteration 3, loss = 2.79461395\n",
      "Validation score: 0.116863\n",
      "Iteration 4, loss = 2.78123770\n",
      "Validation score: 0.119085\n",
      "Iteration 5, loss = 2.77192148\n",
      "Validation score: 0.116419\n",
      "Validation score did not improve more than tol=0.005000 for two consecutive epochs. Stopping.\n",
      "############## one flod is over ##############\n",
      "Iteration 1, loss = 2.88166379\n",
      "Validation score: 0.112864\n",
      "Iteration 2, loss = 2.81368066\n",
      "Validation score: 0.120862\n",
      "Iteration 3, loss = 2.79460421\n",
      "Validation score: 0.113308\n",
      "Iteration 4, loss = 2.78193049\n",
      "Validation score: 0.117529\n",
      "Iteration 5, loss = 2.77125501\n",
      "Validation score: 0.118196\n",
      "Validation score did not improve more than tol=0.005000 for two consecutive epochs. Stopping.\n",
      "############## one flod is over ##############\n"
     ]
    }
   ],
   "source": [
    "train_set, test_set = train_code(train_data, test_data,'label', 22, 10 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.save('new_feature/label_train.npy', train_set)\n",
    "np.save('new_feature/label_test.npy', test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "label_cnt.to_csv('features/label_cnt.csv',index=False)\n",
    "label_tfidf.to_csv('features/label_tfidf.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:python35]",
   "language": "python",
   "name": "conda-env-python35-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
