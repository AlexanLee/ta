{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.metrics import log_loss\n",
    "from help_function import LoadData\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " 设备数据：每个设备上的应用安装列表，设备应用名都进行了hash处理【deviceid_packages.tsv】"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "device_applist = pd.read_csv('../Demo/deviceid_packages.tsv',sep='\\t',\n",
    "                             names=['device_id','app_names'])\n",
    "\n",
    "device_applist['app_names']=device_applist['app_names'].apply(lambda x:x.split(','))\n",
    "device_applist['app_count']=device_applist['app_names'].apply(lambda x:len(x))\n",
    "\n",
    "vectorizer=CountVectorizer()\n",
    "transformer=TfidfTransformer()\n",
    "# 所有设备的应用安装列表\n",
    "apps = device_applist['app_names'].apply(lambda x:' '.join(x)).tolist()\n",
    "# 设备安装应用稀疏矩阵\n",
    "cntTf = vectorizer.fit_transform(apps)\n",
    "# tfidf权重\n",
    "tfidf=transformer.fit_transform(cntTf)\n",
    "# TruncateSVD\n",
    "svd = TruncatedSVD(n_components=550, n_iter=15, random_state=666)\n",
    "# countvector\n",
    "app_svd = svd.fit_transform(cntTf)\n",
    "f_names = ['svd-'+str(x) for x in range(550)]\n",
    "app_svd = pd.DataFrame(app_svd,columns=f_names)\n",
    "# add tfidf_sum columns\n",
    "app_svd['tfidf_sum'] = tfidf.sum(axis=1)\n",
    "device_applist = pd.concat([device_applist, app_svd],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "app_tfidf = svd.fit_transform(tfidf)\n",
    "f_names = ['tfidf'+str(x) for x in range(550)]\n",
    "app_tfidf = pd.DataFrame(app_tfidf, columns=f_names)\n",
    "app_tfidf['device_id'] = device_applist.device_id.values\n",
    "\n",
    "app_svd.to_csv('new_feature/applist_cnt.csv',index=False)\n",
    "app_tfidf.to_csv('new_feature/applist_tfidf.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_path = '../Demo/deviceid_train.tsv'\n",
    "test_path = '../Demo/deviceid_test.tsv'\n",
    "train_data, test_data = LoadData(train_path, test_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge(applist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data = train_data.merge(device_applist, on='device_id',how='left')\n",
    "test_data = test_data.merge(device_applist, on='device_id',how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "label = train_data['sex'].tolist()\n",
    "data = train_data.drop(['device_id','sex','age','label','app_names'],axis=1)\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(data, label, test_size=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLPC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import log_loss\n",
    "import gc\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_code(train_data, test_data,label, num_class, n_folds=5):\n",
    "    labels = train_data[[label]]\n",
    "    train_data = train_data.drop(['device_id','sex','age','label','app_names'],axis=1)\n",
    "    test_data = test_data.drop(['device_id','app_names'],axis=1)\n",
    "    train_predvec = np.zeros((train_data.shape[0], num_class))\n",
    "    test_predvec = np.zeros((test_data.shape[0], num_class))\n",
    "    SKF = StratifiedKFold(n_splits = n_folds, shuffle = True, random_state = 2018)\n",
    "    train_logloss = []\n",
    "    valid_logloss = []\n",
    "    for train_indices, valid_indices in SKF.split(train_data, labels):\n",
    "        # Training data for the fold\n",
    "        x_train = train_data.loc[train_indices, :]\n",
    "        y_train = labels.loc[train_indices, :]\n",
    "        # Validation data for the fold\n",
    "        x_valid = train_data.loc[valid_indices, :]\n",
    "        y_valid = labels.loc[valid_indices, :]\n",
    "        # MLPC\n",
    "        mlpc = MLPClassifier(hidden_layer_sizes=(640,640,640),  #300,300,300\n",
    "                     alpha=0.0033,            \n",
    "                     batch_size=256,          # 256\n",
    "                     learning_rate='adaptive',\n",
    "                     learning_rate_init=0.00054321,\n",
    "                     random_state=666,\n",
    "                     verbose=False,\n",
    "                     early_stopping=True,\n",
    "                     validation_fraction=0.1)       \n",
    "        mlpc.fit(x_train, y_train)\n",
    "        # record logloss\n",
    "        train_logloss.append(log_loss(y_train, mlpc.predict_proba(x_train)))\n",
    "        valid_logloss.append(log_loss(y_valid, mlpc.predict_proba(x_valid)))\n",
    "        train_predvec[valid_indices] = mlpc.predict_proba(x_valid)\n",
    "        test_predvec += mlpc.predict_proba(test_data)/n_folds\n",
    "        # Clean up memory\n",
    "        gc.enable()\n",
    "        del mlpc, x_train, y_train, x_valid, y_valid\n",
    "        gc.collect()\n",
    "        print('############## one flod is over ##############')\n",
    "    train_logloss.append(np.mean(train_logloss))\n",
    "    valid_logloss.append(log_loss(labels, train_predvec))\n",
    "    # dataframe of validation scores\n",
    "    fold_names = list(range(n_folds))\n",
    "    fold_names.append('overall')\n",
    "    # Dataframe of validation scores\n",
    "    metrics = pd.DataFrame({'fold': fold_names,\n",
    "                            'train_logloss':train_logloss,\n",
    "                            'valid_logloss':valid_logloss})\n",
    "    return metrics, train_predvec, test_predvec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 2.77690258\n",
      "Validation score: 0.150700\n",
      "Iteration 2, loss = 2.63101673\n",
      "Validation score: 0.161369\n",
      "Iteration 3, loss = 2.57715410\n",
      "Validation score: 0.164481\n",
      "Iteration 4, loss = 2.54182383\n",
      "Validation score: 0.163814\n",
      "Iteration 5, loss = 2.50057828\n",
      "Validation score: 0.171816\n",
      "Iteration 6, loss = 2.45060442\n",
      "Validation score: 0.154479\n",
      "Iteration 7, loss = 2.39075123\n",
      "Validation score: 0.152478\n",
      "Iteration 8, loss = 2.30357453\n",
      "Validation score: 0.149589\n",
      "Validation score did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "############## one flod is over ##############\n",
      "Iteration 1, loss = 2.77816630\n",
      "Validation score: 0.154667\n",
      "Iteration 2, loss = 2.63061159\n",
      "Validation score: 0.166444\n",
      "Iteration 3, loss = 2.58110395\n",
      "Validation score: 0.168889\n",
      "Iteration 4, loss = 2.54618522\n",
      "Validation score: 0.167111\n",
      "Iteration 5, loss = 2.50870819\n",
      "Validation score: 0.168222\n",
      "Iteration 6, loss = 2.45495486\n",
      "Validation score: 0.165333\n",
      "Validation score did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "############## one flod is over ##############\n",
      "Iteration 1, loss = 2.77634478\n",
      "Validation score: 0.165778\n",
      "Iteration 2, loss = 2.63196861\n",
      "Validation score: 0.175778\n",
      "Iteration 3, loss = 2.58108849\n",
      "Validation score: 0.182889\n",
      "Iteration 4, loss = 2.54498313\n",
      "Validation score: 0.177778\n",
      "Iteration 5, loss = 2.50385306\n",
      "Validation score: 0.180667\n",
      "Iteration 6, loss = 2.44970249\n",
      "Validation score: 0.177556\n",
      "Validation score did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "############## one flod is over ##############\n",
      "Iteration 1, loss = 2.77663920\n",
      "Validation score: 0.158889\n",
      "Iteration 2, loss = 2.63326274\n",
      "Validation score: 0.170000\n",
      "Iteration 3, loss = 2.58344178\n",
      "Validation score: 0.178222\n",
      "Iteration 4, loss = 2.54696870\n",
      "Validation score: 0.170222\n",
      "Iteration 5, loss = 2.50764887\n",
      "Validation score: 0.176222\n",
      "Iteration 6, loss = 2.45801051\n",
      "Validation score: 0.168667\n",
      "Validation score did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "############## one flod is over ##############\n",
      "Iteration 1, loss = 2.77589386\n",
      "Validation score: 0.161556\n",
      "Iteration 2, loss = 2.62955772\n",
      "Validation score: 0.166889\n",
      "Iteration 3, loss = 2.58275207\n",
      "Validation score: 0.171778\n",
      "Iteration 4, loss = 2.54564827\n",
      "Validation score: 0.175111\n",
      "Iteration 5, loss = 2.50757003\n",
      "Validation score: 0.175556\n",
      "Iteration 6, loss = 2.45370797\n",
      "Validation score: 0.165333\n",
      "Iteration 7, loss = 2.39087547\n",
      "Validation score: 0.172000\n",
      "Iteration 8, loss = 2.30365534\n",
      "Validation score: 0.169778\n",
      "Validation score did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "############## one flod is over ##############\n",
      "Iteration 1, loss = 2.78119641\n",
      "Validation score: 0.157521\n",
      "Iteration 2, loss = 2.63370500\n",
      "Validation score: 0.165297\n",
      "Iteration 3, loss = 2.58796679\n",
      "Validation score: 0.174184\n",
      "Iteration 4, loss = 2.54685282\n",
      "Validation score: 0.173961\n",
      "Iteration 5, loss = 2.50862044\n",
      "Validation score: 0.169962\n",
      "Iteration 6, loss = 2.45511288\n",
      "Validation score: 0.170407\n",
      "Validation score did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "############## one flod is over ##############\n",
      "Iteration 1, loss = 2.77632793\n",
      "Validation score: 0.162631\n",
      "Iteration 2, loss = 2.63270179\n",
      "Validation score: 0.171740\n",
      "Iteration 3, loss = 2.58691127\n",
      "Validation score: 0.173961\n",
      "Iteration 4, loss = 2.54696171\n",
      "Validation score: 0.182626\n",
      "Iteration 5, loss = 2.50439186\n",
      "Validation score: 0.171517\n",
      "Iteration 6, loss = 2.45104378\n",
      "Validation score: 0.168185\n",
      "Iteration 7, loss = 2.38363886\n",
      "Validation score: 0.170629\n",
      "Validation score did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "############## one flod is over ##############\n",
      "Iteration 1, loss = 2.77453137\n",
      "Validation score: 0.158187\n",
      "Iteration 2, loss = 2.62868667\n",
      "Validation score: 0.169518\n",
      "Iteration 3, loss = 2.57928999\n",
      "Validation score: 0.173073\n",
      "Iteration 4, loss = 2.54167120\n",
      "Validation score: 0.167963\n",
      "Iteration 5, loss = 2.50187313\n",
      "Validation score: 0.169074\n",
      "Iteration 6, loss = 2.44806587\n",
      "Validation score: 0.170407\n",
      "Validation score did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "############## one flod is over ##############\n",
      "Iteration 1, loss = 2.77897161\n",
      "Validation score: 0.152855\n",
      "Iteration 2, loss = 2.63520480\n",
      "Validation score: 0.169962\n",
      "Iteration 3, loss = 2.58715786\n",
      "Validation score: 0.171073\n",
      "Iteration 4, loss = 2.54884943\n",
      "Validation score: 0.182404\n",
      "Iteration 5, loss = 2.50939579\n",
      "Validation score: 0.171073\n",
      "Iteration 6, loss = 2.46005324\n",
      "Validation score: 0.172406\n",
      "Iteration 7, loss = 2.39111213\n",
      "Validation score: 0.165074\n",
      "Validation score did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "############## one flod is over ##############\n",
      "Iteration 1, loss = 2.77037612\n",
      "Validation score: 0.160187\n",
      "Iteration 2, loss = 2.62932205\n",
      "Validation score: 0.179960\n",
      "Iteration 3, loss = 2.58367641\n",
      "Validation score: 0.174628\n",
      "Iteration 4, loss = 2.54535256\n",
      "Validation score: 0.175739\n",
      "Iteration 5, loss = 2.50648792\n",
      "Validation score: 0.169518\n",
      "Validation score did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "############## one flod is over ##############\n"
     ]
    }
   ],
   "source": [
    "metric, train_set, test_set = train_code(train_data, test_data,'label', 22, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.save('new_feature/applist_train.npy',train_set)\n",
    "np.save('new_feature/applist_test.npy',test_set)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:python35]",
   "language": "python",
   "name": "conda-env-python35-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
