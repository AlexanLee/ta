{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import gc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold,StratifiedKFold\n",
    "from sklearn.metrics import log_loss\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.optimizers import RMSprop, Adam\n",
    "from keras.utils import np_utils\n",
    "from keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "%matplotlib inline\n",
    "np.random.seed(1671) # for reproducibility\n",
    "from help_function import LoadData"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Train/test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_datapath =  '../Demo/deviceid_train.tsv' \n",
    "test_datapath =  '../Demo/deviceid_test.tsv' \n",
    "train_data, test_data = LoadData(train_datapath, test_datapath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load new features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "applist_train = np.load('new_feature/applist_train.npy')\n",
    "applist_test = np.load('new_feature/applist_test.npy')\n",
    "label_train = np.load('new_feature/label_train.npy')\n",
    "label_test = np.load('new_feature/label_test.npy')\n",
    "h1_train = np.load('new_feature/h1_train.npy')\n",
    "h1_test = np.load('new_feature/h1_test.npy')\n",
    "h2_train = np.load('new_feature/h2_train.npy')\n",
    "h2_test = np.load('new_feature/h2_test.npy')\n",
    "h3_train = np.load('new_feature/h3_train.npy')\n",
    "h3_test = np.load('new_feature/h3_test.npy')\n",
    "b1_train = np.load('new_feature/brand_train.npy')\n",
    "b1_test = np.load('new_feature/brand_test.npy')\n",
    "age_train = np.load('new_feature/age_train.npy')\n",
    "age_test = np.load('new_feature/age_test.npy')\n",
    "sex_train = np.load('new_feature/sex_train.npy')\n",
    "sex_test = np.load('new_feature/sex_test.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lgbtrain = np.load('new_feature/lgbcnt_train.npy')\n",
    "lgbtest = np.load('new_feature/lgbcnt_test.npy')\n",
    "\n",
    "lgbtfidf_train = np.load('new_feature/lgbtfidf_train.npy')\n",
    "lgbtfidf_test = np.load('new_feature/lgbtfidf_test.npy')\n",
    "\n",
    "lgbbagetrain = np.load('new_feature/lgbbage_train.npy')\n",
    "lgbbagetest = np.load('new_feature/lgbbage_test.npy')\n",
    "lgbbsextrain = np.load('new_feature/lgbbsex_train.npy')\n",
    "lgbbsextest = np.load('new_feature/lgbbsex_test.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_set = np.concatenate([applist_train, h1_train,h2_train,b1_train,\n",
    "                            lgbtrain,lgbtfidf_train,lgbbagetrain,lgbbsextrain,\n",
    "                            h3_train,age_train,sex_train,\n",
    "                            label_train],axis=1)\n",
    "test_set = np.concatenate([applist_test, h1_test,h2_test,b1_test,\n",
    "                           lgbtest,lgbtfidf_test,lgbbagetest,lgbbsextest ,\n",
    "                           h3_test,age_test, sex_test,\n",
    "                           label_test],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set.shape, test_set.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def NNmodel(N_HIDDEN,Input_shape, DROPOUT, NB_CLASSES):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(N_HIDDEN, input_shape=(Input_shape,)))\n",
    "    model.add(Activation('relu'))\n",
    "    #model.add(Dropout(0.2))\n",
    "    model.add(Dense(N_HIDDEN))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(DROPOUT))\n",
    "    model.add(Dense(N_HIDDEN))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(DROPOUT))\n",
    "    model.add(Dense(N_HIDDEN))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(DROPOUT))\n",
    "    model.add(Dense(N_HIDDEN))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(NB_CLASSES))\n",
    "    model.add(Activation('softmax'))\n",
    "    model.compile(loss='categorical_crossentropy',optimizer=Adam(lr=0.0003, decay=0),\n",
    "              metrics=['accuracy'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def CVtrain(train_data, test_data,labels, num_class, n_folds=5):\n",
    "    train_predvec = np.zeros((train_data.shape[0], num_class))\n",
    "    test_predvec = np.zeros((test_data.shape[0], num_class))\n",
    "    SKF = StratifiedKFold(n_splits = n_folds, shuffle = True, random_state = 2018)\n",
    "    train_logloss = []\n",
    "    valid_logloss = []\n",
    "    for train_indices, valid_indices in SKF.split(train_data,labels):\n",
    "        # Training data for the fold\n",
    "        x_train = train_data[train_indices, :]\n",
    "        y_train = labels.loc[train_indices, :]\n",
    "        # Validation data for the fold\n",
    "        x_valid = train_data[valid_indices, :]\n",
    "        y_valid = labels.loc[valid_indices, :]\n",
    "        # NNmodel\n",
    "        y_train = np_utils.to_categorical(y_train, num_class)\n",
    "        y_valid = np_utils.to_categorical(y_valid, num_class)\n",
    "        model = NNmodel(700, 202, 0.25, num_class)\n",
    "        learning_rate_reduction = ReduceLROnPlateau(monitor = 'val_loss', \n",
    "                                            patience = 3,mode='min',\n",
    "                                            min_delta = 0.001,\n",
    "                                            verbose = 2, factor=0.3, min_lr = 0.00001) \n",
    "        model.fit(x_train, y_train,batch_size=300,epochs=40,verbose=2,\n",
    "                  validation_data=(x_valid, y_valid),\n",
    "                  callbacks=[learning_rate_reduction])\n",
    "        # record logloss\n",
    "        train_logloss.append(log_loss(y_train, model.predict_proba(x_train)))\n",
    "        valid_logloss.append(log_loss(y_valid, model.predict_proba(x_valid)))\n",
    "        train_predvec[valid_indices] = model.predict_proba(x_valid)\n",
    "        test_predvec += model.predict_proba(test_data)/n_folds\n",
    "        # Clean up memory\n",
    "        gc.enable()\n",
    "        del model, x_train, y_train, x_valid, y_valid\n",
    "        gc.collect()\n",
    "        print('############## one flod is over ##############')\n",
    "    train_logloss.append(np.mean(train_logloss))\n",
    "    valid_logloss.append(log_loss(labels, train_predvec))\n",
    "    # dataframe of validation scores\n",
    "    fold_names = list(range(n_folds))\n",
    "    fold_names.append('overall')\n",
    "    # Dataframe of validation scores\n",
    "    metrics = pd.DataFrame({'fold': fold_names,\n",
    "                            'train_logloss':train_logloss,\n",
    "                            'valid_logloss':valid_logloss})\n",
    "    return metrics, train_predvec, test_predvec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels = train_data[['label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%time metric, train, test = CVtrain(train_set, test_set, labels, 22, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_submit(result,test_id):\n",
    "    result = pd.DataFrame(result,\n",
    "                          columns=['1-0', '1-1', '1-2', '1-3', '1-4', '1-5', '1-6', '1-7',\n",
    "                                   '1-8', '1-9', '1-10', '2-0', '2-1', '2-2', '2-3','2-4', '2-5', '2-6', '2-7', '2-8', \n",
    "                                   '2-9', '2-10'])\n",
    "    result['DeviceID'] = test_id.values\n",
    "    result = result[['DeviceID']+list(result.columns[:-1])]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result = make_submit(test, test_data.device_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result.to_csv('submit/sub4.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:python35]",
   "language": "python",
   "name": "conda-env-python35-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
