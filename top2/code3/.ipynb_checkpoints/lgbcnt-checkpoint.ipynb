{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import KFold,StratifiedKFold,train_test_split\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import warnings\n",
    "from help_function import LoadData\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "applist = pd.read_csv('features/applist_cnt.csv')\n",
    "labelcnt = pd.read_csv('features/label_cnt.csv')\n",
    "brand = pd.read_csv('features/brand100.csv')\n",
    "h1 = pd.read_csv('features/h1.csv')\n",
    "h2 = pd.read_csv('features/h2_cnt300.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# trian data , test data\n",
    "# train test data\n",
    "train_datapath =  '../Demo/deviceid_train.tsv' \n",
    "test_datapath =  '../Demo/deviceid_test.tsv' \n",
    "train_data, test_data = LoadData(train_datapath, test_datapath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data = train_data.merge(applist, on='device_id',how='left')\n",
    "train_data = train_data.merge(labelcnt, on='device_id',how='left')\n",
    "train_data = train_data.merge(brand, on='device_id',how='left')\n",
    "train_data = train_data.merge(h1, on='device_id', how='left')\n",
    "train_data = train_data.merge(h2, on='device_id', how='left')\n",
    " \n",
    "\n",
    "test_data = test_data.merge(applist, on='device_id',how='left')\n",
    "test_data =  test_data.merge(labelcnt, on='device_id',how='left')\n",
    "test_data = test_data.merge(brand, on='device_id', how='left')\n",
    "test_data = test_data.merge(h1, on='device_id', how='left')\n",
    "test_data = test_data.merge(h2, on='device_id', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def FeatureSelect(train_data, label='label', num_class=22, obj='multiclass',\n",
    "                  metric='multi_logloss'):\n",
    "    # binary   , binary_logloss\n",
    "    model = lgb.LGBMClassifier(boosting_type='gbdt',n_estimators=1000, colsample_bytree=1,\n",
    "                               objective = obj,max_depth=3,learning_rate = 0.1,\n",
    "                               num_leaves =31, num_class=num_class,reg_lambda = 1.,\n",
    "                               reg_alpha = 1, n_jobs = -1,random_state = 8082)\n",
    "    # split train valid data\n",
    "    y = train_data[[label]]\n",
    "    data = train_data.drop(['device_id','sex','age','label'],axis=1)\n",
    "    x_train, x_valid, y_train, y_valid = train_test_split(data, y, test_size=0.1,random_state=666)\n",
    "    # fit\n",
    "    model.fit(x_train, y_train, eval_metric = metric,\n",
    "              eval_set = [(x_train, y_train),(x_valid, y_valid)],\n",
    "              eval_names = ['train','valid'],\n",
    "              early_stopping_rounds = 10, verbose = 0) \n",
    "    feature_importance = pd.DataFrame()\n",
    "    feature_importance['feature'] = x_train.columns.values\n",
    "    feature_importance['importrance'] = model.feature_importances_\n",
    "    useless_feature = feature_importance[feature_importance.importrance==0].feature.tolist()\n",
    "    return useless_feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CV train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model(train_data, test_data,label, num_class, n_folds = 10,\n",
    "         obj='multiclass',metric='multi_logloss'):\n",
    "    \n",
    "    #binary ; log_loss\n",
    "    labels = train_data[[label]]\n",
    "    train_data = train_data.drop(['device_id','sex','age','label'],axis=1)\n",
    "    test_data = test_data.drop(['device_id'],axis=1)\n",
    "    # 10 folds cross validation\n",
    "    SKF = StratifiedKFold(n_splits = n_folds, shuffle = True, random_state = 2018)\n",
    "    # test predictions\n",
    "    test_predictions = np.zeros((test_data.shape[0],num_class))\n",
    "    # validation predictions\n",
    "    out_of_fold = np.zeros((train_data.shape[0],num_class))\n",
    "    # record scores : logloss\n",
    "    train_logloss = []\n",
    "    valid_logloss = []\n",
    "    # Iterate through each fold\n",
    "    for train_indices, valid_indices in SKF.split(train_data,labels):\n",
    "        # Training data for the fold\n",
    "        train_features = train_data.loc[train_indices, :]\n",
    "        train_labels = labels.loc[train_indices, :]\n",
    "        # Validation data for the fold\n",
    "        valid_features = train_data.loc[valid_indices, :]\n",
    "        valid_labels = labels.loc[valid_indices, :]\n",
    "        # Create the model\n",
    "        model = lgb.LGBMClassifier(boosting_type='gbdt',n_estimators=1000, \n",
    "                                   objective = obj ,max_depth=3,\n",
    "                                   learning_rate = 0.1,  num_leaves =31,num_class=num_class,\n",
    "                                   reg_lambda = 1.,reg_alpha = 1,\n",
    "                                   subsample = 1., n_jobs = -1, random_state = 8082)\n",
    "\n",
    "        # Train the model\n",
    "        model.fit(train_features, train_labels, eval_metric = metric,\n",
    "                  eval_set = [(valid_features, valid_labels), (train_features, train_labels)],\n",
    "                  eval_names = ['valid', 'train'], #categorical_feature =['brand','type','btype'],\n",
    "                  early_stopping_rounds = 10, verbose = 0)\n",
    "        # Record the best iteration\n",
    "        best_iteration = model.best_iteration_\n",
    "        # test result\n",
    "        test_predictions+= model.predict_proba(test_data, num_iteration = best_iteration)/n_folds\n",
    "        # valid result\n",
    "        pred_valid = model.predict_proba(valid_features, num_iteration = best_iteration)\n",
    "        # Record the best multi logloss\n",
    "        valid_score = model.best_score_['valid'][metric]\n",
    "        train_score = model.best_score_['train'][metric]\n",
    "        valid_logloss.append(valid_score)\n",
    "        train_logloss.append(train_score)\n",
    "        # validation set result\n",
    "        out_of_fold[valid_indices] = pred_valid\n",
    "        print('train loss is : %.5f  |  valid loss is : %.5f'%(train_score,valid_score))\n",
    "        # Clean up memory\n",
    "        gc.enable()\n",
    "        del model, train_features, valid_features\n",
    "        gc.collect()\n",
    "    # overall valida\n",
    "    valid_logloss.append(np.mean(valid_logloss))\n",
    "    train_logloss.append(np.mean(train_logloss))\n",
    "    # dataframe of validation scores\n",
    "    fold_names = list(range(n_folds))\n",
    "    fold_names.append('overall')\n",
    "    # Dataframe of validation scores\n",
    "    metrics = pd.DataFrame({'fold': fold_names,\n",
    "                            'train_logloss':train_logloss,\n",
    "                            'valid_logloss':valid_logloss})\n",
    "    return metrics,out_of_fold,test_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "useless_feature = FeatureSelect(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = train_data.drop(useless_feature, axis=1)\n",
    "test = test_data.drop(useless_feature, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time metric, train_proba, test_proba = model(train, test, 'label', 22, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.save('new_feature/lgbcnt_train.npy',train_proba)\n",
    "np.save('new_feature/lgbcnt_test.npy',test_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:python35]",
   "language": "python",
   "name": "conda-env-python35-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
